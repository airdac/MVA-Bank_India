---
title: "PCA MVA-11-BANK_INDIA"
author: "Adri√† Casanova Lloveras"
date: "2023-10-26"
output: html_document
---

# Read data
```{r}
df <- read.csv("imputed_data.csv")
data = df
```

##### PCA #####

# Firstly, we did a PCA only for numerical variables to see how the variables are related. The result of the 9 principal components shows that keeping first 5 components are required in order to explain 80% of the accumulated inertia. 
# Using the two main components (50% of accumulated inertia) we can see that how variables like "price", "credit" and "loan" have the most extreme values of PC1 whereas "income" is located at the middle. This suggest that the first axis is related to an economical pattern. While in the second axis, it's related with time, such as age and job duration. 
#~The n_child is seems to be an outlier, but we'll comment it later.

```{r, include=FALSE}
# Here we can see the output of the PCA 
numeriques <- which(sapply(data,is.numeric))
numeriques

dcon <- data[,numeriques]
sapply(dcon,class)

pc1 <- prcomp(dcon, scale=TRUE)
pc1
```

# Accumulated Inertia in subspace, from first principal component to the 11th dimension subspace. Which we can observe that 5 components are required in order to achieve the 80% of accumulated inertia.
```{r}
barplot(100*cumsum(pc1$sdev[1:dim(dcon)[2]]^2)/dim(dcon)[2], main = 
        'Analysis of principal components', 
        names.arg = c("PC1", "PC2", "PC3", "PC4", "PC5",
        "PC6", "PC7", "PC8", "PC9"), ylab = "Cumulative total inertia (%)")

abline(80,0, col = "blue", lwd = 2, lty = 2)
axis(side=2, at=(seq(0, 100, by=10)), labels = FALSE)

```

# PCA plot construction
```{r, include=FALSE}
# Select only 5 components
nd = 5
Psi = pc1$x[,1:nd]

# STORAGE OF LABELS FOR INDIVIDUALS AND VARIABLES

iden = row.names(dcon)
etiq = names(dcon)
ze = rep(0,length(etiq)) # WE WILL NEED THIS VECTOR AFTERWARDS FOR THE GRAPHICS

# PLOT OF INDIVIDUALS

#Select the component to be plot on our axis
eje1<-1
eje2<-2

# Here is were we create the shadows

plot(Psi[,eje1],Psi[,eje2])
text(Psi[,eje1],Psi[,eje2],labels=iden, cex=0.5)
axis(side=1, pos= 0, labels = F, col="cyan")
axis(side=3, pos= 0, labels = F, col="cyan")
axis(side=2, pos= 0, labels = F, col="cyan")
axis(side=4, pos= 0, labels = F, col="cyan")

# Now don't display the nodes

plot(Psi[,eje1],Psi[,eje2], type="n")
text(Psi[,eje1],Psi[,eje2],labels=iden, cex=0.5)
axis(side=1, pos= 0, labels = F, col="cyan")
axis(side=3, pos= 0, labels = F, col="cyan")
axis(side=2, pos= 0, labels = F, col="cyan")
axis(side=4, pos= 0, labels = F, col="cyan")

#Projection of variables
# Correlation between original variables and the principal components
Phi = cor(dcon,Psi)

#select our axis

X<-Phi[,eje1]
Y<-Phi[,eje2]

plot(Psi[,eje1],Psi[,eje2],type="n")
axis(side=1, pos= 0, labels = F)
axis(side=3, pos= 0, labels = F)
axis(side=2, pos= 0, labels = F)
axis(side=4, pos= 0, labels = F)
arrows(ze, ze, X, Y, length = 0.07,col="blue")
text(X,Y,labels=etiq,col="darkblue", cex=0.7)

plot(Psi[,eje1],Psi[,eje2], type="n")
#text(Psi[,eje1],Psi[,eje2],labels=iden, cex=0.5)
axis(side=1, pos= 0, labels = F, col="cyan")
axis(side=3, pos= 0, labels = F, col="cyan")
axis(side=2, pos= 0, labels = F, col="cyan")
axis(side=4, pos= 0, labels = F, col="cyan")
```

# Projecting the PCA in the Factorial plan.
```{r}
plot(Psi[,eje1],Psi[,eje2],type="n", xlim = c(-1,0.01), ylim = c(-1, 1),
     main = '', xlab = 'PC1', ylab='PC2')
axis(side=1, pos= 0, labels = F)
axis(side=3, pos= 0, labels = F)
axis(side=2, pos= 0, labels = F)
axis(side=4, pos= 0, labels = F)
# arrows(ze, ze, X, Y, length = 0.07,col="blue")
text(X,Y,labels=etiq,col="darkblue", cex=0.8)
text(-0.65,-0.7, 
     substitute(paste(italic('Note: "price" and "credit" share almost the same space')))
     ,col="red", cex=0.8)

# The "price" and "credit" are overlap, because one is the price of the good that they want to purchase, while the credit is the loan that the client request. And in most of the cases, they are really similar.
# The n_child seems to be opposite than age, which is kind of controversial. The reason of that is, based on the sample size that we are investigating, the younger age tend to have more child than older people.
```

# Zoom to see the aggregated variables among the negative first component
```{r, include=FALSE}
plot(Psi[,eje1],Psi[,eje2],type="n", xlim = c(-1,-0.7), ylim = c(-0.2, 0.2))
axis(side=1, pos= 0, labels = F)
axis(side=3, pos= 0, labels = F)
axis(side=2, pos= 0, labels = F)
axis(side=4, pos= 0, labels = F)
arrows(ze, ze, X, Y, length = 0.07,col="blue")
text(X,Y,labels=etiq,col="darkblue", cex=0.7)

# Check that there are not more variables aggregated close to "loan"

plot(Psi[,eje1],Psi[,eje2],type="n", xlim = c(-1,-0.85), ylim = c(-0.1, 0))
axis(side=1, pos= 0, labels = F)
axis(side=3, pos= 0, labels = F)
axis(side=2, pos= 0, labels = F)
axis(side=4, pos= 0, labels = F)
arrows(ze, ze, X, Y, length = 0.07,col="blue")
text(X,Y,labels=etiq,col="darkblue", cex=0.7)
```

# To have a better understanding of the factorial planes the target variable "pay" was added into the map. Note that the figure shows that there is a difference on loans that are "payed" or "overdue"

```{r}
# Adding the target variable (index=2)
varcat=factor(data[,2])
plot(Psi[,1],Psi[,2], pch=c(1,20) [varcat], col=c("lightgreen", "red") [varcat],
     xlab = 'PC1', ylab = 'PC2')
axis(side=1, pos= 0, labels = F, col="darkgray")
axis(side=3, pos= 0, labels = F, col="darkgray")
axis(side=2, pos= 0, labels = F, col="darkgray")
axis(side=4, pos= 0, labels = F, col="darkgray")
legend(levels(factor(varcat)),pch=c(1,20),col=c(1,2), cex=0.6)

text(fdic1,fdic2,labels=levels(varcat), col=c("darkblue", "darkblue"), 
     cex=0.7)

```

# If we take a loop in the centroid of distribution of "paid" and "overdue", where's the result.
```{r, include=FALSE}
varcat<-factor(data[,2]) 
fdic1 = tapply(Psi[,eje1],varcat,mean)
fdic2 = tapply(Psi[,eje2],varcat,mean) 

plot(Psi[,eje1],Psi[,eje2],type="n", xlim= c(-1,1), ylim = c(-1,1))
axis(side=1, pos= 0, labels = F, col="cyan")
axis(side=3, pos= 0, labels = F, col="cyan")
axis(side=2, pos= 0, labels = F, col="cyan")
axis(side=4, pos= 0, labels = F, col="cyan")

text(fdic1,fdic2,labels=levels(varcat), col=c("green", "red"), 
     cex=0.7)
```

# Adding the categorical feature in the factorial plan to find the correlation between variables.
```{r, include=FALSE}
dcat <- c(2:5,11:14,17:18,20)
colors<-rainbow(length(dcat))

plot(Psi[,eje1],Psi[,eje2], type = "n")
axis(side=1, pos= 0, labels = F, col="cyan")
axis(side=3, pos= 0, labels = F, col="cyan")
axis(side=2, pos= 0, labels = F, col="cyan")
axis(side=4, pos= 0, labels = F, col="cyan")

# Loop to add all categories 

c <- 1
for(k in dcat){
  seguentColor<-colors[c]
  fdic1 = tapply(Psi[,eje1],data[,k],mean)
  fdic2 = tapply(Psi[,eje2],data[,k],mean) 
  
  text(fdic1,fdic2,labels=levels(factor(data[,k])),col=seguentColor, cex=0.6)
  c<-c+1
}
legend("bottomleft",names(data)[dcat],pch=1,col=colors, cex=0.6)

```

# A zoom is required 
```{r, include=FALSE}
dcat <- c(2:5,11:14,17:18,20)
colors<-rainbow(length(dcat))

plot(Psi[,eje1],Psi[,eje2], type = "n", xlim = c(-3,2), ylim = c(-2,3))
axis(side=1, pos= 0, labels = F, col="cyan")
axis(side=3, pos= 0, labels = F, col="cyan")
axis(side=2, pos= 0, labels = F, col="cyan")
axis(side=4, pos= 0, labels = F, col="cyan")

# Loop to add all categories 

c <- 1
for(k in dcat){
  seguentColor<-colors[c]
  fdic1 = tapply(Psi[,eje1],data[,k],mean)
  fdic2 = tapply(Psi[,eje2],data[,k],mean) 
  
  text(fdic1,fdic2,labels=levels(factor(data[,k])),col=seguentColor, cex=0.6)
  c<-c+1
}
legend("bottomleft",names(data)[dcat],pch=1,col=colors, cex=0.6)

```


# As there are too much variables its important to do several maps that will share the same length of the axis to be comparable visually 
# Note: There is a bug in the visualization. The last plot seams smaller but when you save the figure all of them have the same size
```{r}
groups <- list(c(2:5), c(11:13), 14, 17, 18, 20)

for(j in 1:length(groups)){
  colors <- rainbow(length(groups))
  
  a = plot(Psi[,eje1],Psi[,eje2], type = "n", xlim = c(-3,2), ylim = c(-2,3))
  axis(side=1, pos= 0, labels = F, col="cyan")
  axis(side=3, pos= 0, labels = F, col="cyan")
  axis(side=2, pos= 0, labels = F, col="cyan")
  axis(side=4, pos= 0, labels = F, col="cyan")
    
    # Loop to add all categories of this group
    c <- 1
    for(k in groups[[j]]){
      seguentColor<-colors[c]
      fdic1 = tapply(Psi[,eje1],data[,k],mean)
      fdic2 = tapply(Psi[,eje2],data[,k],mean) 
      
      text(fdic1,fdic2,labels=levels(factor(data[,k])),col=seguentColor, 
           cex=0.6)
      c <- c+1
    }
  legend("bottomleft",names(data)[groups[[j]]],pch=1,col=colors, cex=0.6)
}


```

# Numerical variables and centroids of desired categorical variables
# Several maps are created to see relations
```{r}
groups <- list(c(2:5), c(11:13))

for(j in 1:length(groups)){
  colors <- rainbow(length(groups))
  
  a = plot(Psi[,eje1],Psi[,eje2], type = "n", xlim = c(-1,2), ylim = c(-1,3))
  axis(side=1, pos= 0, labels = F, col="cyan")
  axis(side=3, pos= 0, labels = F, col="cyan")
  axis(side=2, pos= 0, labels = F, col="cyan")
  axis(side=4, pos= 0, labels = F, col="cyan")
  
  #add projections of numerical variables in background
  arrows(ze, ze, X, Y, length = 0.07,col="lightgray")
  text(X,Y,labels=etiq,col="gray", cex=0.7)
    
    # Loop to add all categories of this group
    c <- 1
    for(k in groups[[j]]){
      seguentColor<-colors[c]
      fdic1 = tapply(Psi[,eje1],data[,k],mean)
      fdic2 = tapply(Psi[,eje2],data[,k],mean) 
      
      text(fdic1,fdic2,labels=levels(factor(data[,k])),col=seguentColor, 
           cex=0.6)
      c <- c+1
    }
  legend("bottomleft",names(data)[groups[[j]]],pch=1,col=colors, cex=0.6)
}

```


##### Outlier detection #####

# Once we have the PCA (1rst and 2n component), we can use Mahalanobis distance to detect outlier using with a cutoff of 95%. The orange elipse circle project the 95% of confidence level, while the record outside the surface will be considered as outlier

```{r}
# Plot the PCA plan
plot(Psi[,eje1],Psi[,eje2])
axis(side=1, pos= 0, labels = F, col="cyan")
axis(side=3, pos= 0, labels = F, col="cyan")
axis(side=2, pos= 0, labels = F, col="cyan")
axis(side=4, pos= 0, labels = F, col="cyan")

# Defining the parameter for Mahalanobis distance
df <- Psi[,eje1:eje2]
df.center <- colMeans(df)
df.cov <- cov(df)
rad <- sqrt(qchisq(0.95, df = ncol(df)))


# Plotting the ellipse of Mahalanobis distance
ellipse <- data.frame(ellipse(df.center, df.cov, rad, 100, FALSE, col = "orange", fill=TRUE))
```

# Then applying the Mahalanobis distance and the cut-off threshold, we'll find our data treated.
```{r}
# Applying the function
distances <- mahalanobis(x = df, center = df.center, cov = df.cov)

# Defining the Cut-off trigger using Chi-square distance with p = 0.95 df = 2 which in ncol(df)
cutoff <- qchisq(p = 0.95 , df = ncol(df))

# Display all the observations whose distance is greater than the cut-off value.
df[distances > cutoff ,]

# Displan only the observation within the distance
df_clean <- df[distances < cutoff ,]
plot(df_clean, type = "p")
# text(Psi[,eje1],Psi[,eje2],labels=iden,  cex=0.5)
axis(side=1, pos= 0, labels = F, col="cyan")
axis(side=3, pos= 0, labels = F, col="cyan")
axis(side=2, pos= 0, labels = F, col="cyan")
axis(side=4, pos= 0, labels = F, col="cyan")
```


```{r}
#select other axes

eje1 = 3
eje2 = 4

X<-Phi[,eje1]
Y<-Phi[,eje2]

plot(Psi[,eje1],Psi[,eje2],type="n", xlim = c(-.2,1), ylim = c(-1,.2))
axis(side=1, pos= 0, labels = F)
axis(side=3, pos= 0, labels = F)
axis(side=2, pos= 0, labels = F)
axis(side=4, pos= 0, labels = F)
arrows(ze, ze, X, Y, length = 0.07,col="blue")
text(X,Y,labels=etiq,col="darkblue", cex=0.7)
```
It seems that the 4th axis is only related with the id attribute, while the 3rd
might be how often the client accesses the bank. Since they are only
related to variables we already possess, we can conclude that these 
factorial axes aren't relevant in our analysis.

Find relation between age and n_child
```{r}
# df <- data.frame(data$n_child, age)

# Calculate the average age for each n_child value
avg_age <- tapply(data$age, data$n_child, mean)
regression_model <- lm(data$age ~ data$n_child, data = data)
```

```{r}
# Create the scatter plot
plot(names(avg_age), avg_age, xlab = "n_child", ylab = "Average Age", main = "Average Age vs. n_child")
abline(regression_model, col = "blue")
```

Plot avg(age) ~ n_child
```{r}
par(mfrow=c(1,1))
plot (data$n_child, data$age)
```

Regression model results
```{r}
regression_model
summary(regression_model)
```

Regression model plots
```{r}
par(mfrow=c(2,2))
plot(regression_model)
```

