---
title: "PCA MVA-11-BANK_INDIA"
author: "Adri√† Casanova Lloveras"
date: "2023-10-26"
output: html_document
---
# Load libraries
```{r}
library(car)
```



# Read data
```{r}
df <- read.csv("Bank-India-preprocessed-data.csv")
data = df
```

##### PCA #####

# Firstly, we did a PCA only with the numerical variables to study their relation. The result shows that out of 9 principal components, the first 5 are enough to explain 80% of the accumulated inertia. 
# Using the two main components (50% of accumulated inertia) we can see how variables like "price", "credit" and "loan" have the most extreme values of PC1 whereas "income" is located at the middle. This suggest that the first axis describes the wealth of the costumer. Moving left, wealth increases. On the other hand, the second axis represents time, since it's very correlated to age and job_duration. The number of children decreases as time grows, as we have shown in the EDA.

```{r, include=FALSE}
# Here we can see the output of the PCA 
numeriques <- which(sapply(data,is.numeric))
# We don't include id for the analysis
numeriques = numeriques[-1]

dcon <- data[,numeriques]
sapply(dcon,class)

pc1 <- prcomp(dcon, scale=TRUE)
pc1
```

# Accumulated Inertia
```{r}
barplot(100*cumsum(pc1$sdev[1:dim(dcon)[2]]^2)/dim(dcon)[2], main = 
        'Analysis of principal components', 
        names.arg = c("PC1", "PC2", "PC3", "PC4", "PC5",
        "PC6", "PC7", "PC8"), ylab = "Cumulative total inertia (%)")

abline(80,0, col = "blue", lwd = 2, lty = 2)
axis(side=2, at=(seq(0, 100, by=10)), labels = FALSE)

```

# PCA plot construction
```{r, include=FALSE}
# Select only 4 components
nd = 4
Psi = pc1$x[,1:nd]

# STORAGE OF LABELS FOR INDIVIDUALS AND VARIABLES

iden = row.names(dcon)
etiq = names(dcon)
ze = rep(0,length(etiq)) # WE WILL NEED THIS VECTOR AFTERWARDS FOR THE GRAPHICS

# PLOT OF INDIVIDUALS

#Select the component to be plot on our axis
eje1<-1
eje2<-2

# Here is were we create the shadows

plot(Psi[,eje1],Psi[,eje2], type="n")
text(Psi[,eje1],Psi[,eje2],labels=iden, cex=0.5)
axis(side=1, pos= 0, labels = F, col="cyan")
axis(side=3, pos= 0, labels = F, col="cyan")
axis(side=2, pos= 0, labels = F, col="cyan")
axis(side=4, pos= 0, labels = F, col="cyan")


# Projection of variables
# Correlation between original variables and the principal components
Phi = cor(dcon,Psi)

#select our axes

X<-Phi[,eje1]
Y<-Phi[,eje2]

plot(Psi[,eje1],Psi[,eje2],type="n")
axis(side=1, pos= 0, labels = F)
axis(side=3, pos= 0, labels = F)
axis(side=2, pos= 0, labels = F)
axis(side=4, pos= 0, labels = F)
arrows(ze, ze, X, Y, length = 0.07,col="blue")
text(X,Y,labels=etiq,col="darkblue", cex=0.7)
```

# Projecting the PCA in the Factorial plane.
```{r}
plot(Psi[,eje1],Psi[,eje2],type="n", xlim = c(0,1), ylim = c(-1, 1),
     main = '', xlab = 'PC1', ylab='PC2')
axis(side=1, pos= 0, labels = F)
axis(side=3, pos= 0, labels = F)
axis(side=2, pos= 0, labels = F)
axis(side=4, pos= 0, labels = F)
arrows(ze, ze, X, Y, length = 0.07,col="blue")
text(X,Y,labels=etiq,col="darkblue", cex=0.8)
text(-0.65,-0.7, 
     substitute(paste(italic('Note: "price" and "credit" share almost the same space')))
     ,col="red", cex=0.8)

# "price" and "credit" overlap because one is the price of the good to purchase, while credit is the loan the client requests.
```

# Zoom to see the variables aggregated in the negative side of the first component
```{r, include=FALSE}
plot(Psi[,eje1],Psi[,eje2],type="n", xlim = c(0.7,1), ylim = c(-0.2, 0.2))
axis(side=1, pos= 0, labels = F)
axis(side=3, pos= 0, labels = F)
axis(side=2, pos= 0, labels = F)
axis(side=4, pos= 0, labels = F)
arrows(ze, ze, X, Y, length = 0.07,col="blue")
text(X,Y,labels=etiq,col="darkblue", cex=0.7)

# Check that there are not more variables aggregated close to "loan"

plot(Psi[,eje1],Psi[,eje2],type="n", xlim = c(0.85,1), ylim = c(-0.1, 0))
axis(side=1, pos= 0, labels = F)
axis(side=3, pos= 0, labels = F)
axis(side=2, pos= 0, labels = F)
axis(side=4, pos= 0, labels = F)
arrows(ze, ze, X, Y, length = 0.07,col="blue")
text(X,Y,labels=etiq,col="darkblue", cex=0.7)
```

# To have a better understanding of the factorial planes the target variable "pay" was added into the map. Note that the figure shows that there is a difference on loans that are "payed" or "overdue"

```{r}
# Adding the target variable (index=2)

varcat<-factor(data[,2]) 
fdic1 = tapply(Psi[,eje1],varcat,mean)
fdic2 = tapply(Psi[,eje2],varcat,mean) 

varcat=factor(data[,2])
plot(Psi[,1],Psi[,2], pch=c(1,20) [varcat], col=c("black", "red") [varcat],
     xlab = 'PC1', ylab = 'PC2')
axis(side=1, pos= 0, labels = F, col="darkgray")
axis(side=3, pos= 0, labels = F, col="darkgray")
axis(side=2, pos= 0, labels = F, col="darkgray")
axis(side=4, pos= 0, labels = F, col="darkgray")
legend("bottomleft",levels(factor(varcat)),pch=c(1,20),col=c(1,2), cex=0.6)

text(fdic1,fdic2,labels=levels(varcat), col=c("darkblue", "darkblue"), 
     cex=0.7)

```

# If we take a loop in the centroid of distribution of "paid" and "overdue", where's the result.
```{r, include=FALSE}

plot(Psi[,eje1],Psi[,eje2],type="n", xlim= c(-1,1), ylim = c(-1,1))
axis(side=1, pos= 0, labels = F, col="cyan")
axis(side=3, pos= 0, labels = F, col="cyan")
axis(side=2, pos= 0, labels = F, col="cyan")
axis(side=4, pos= 0, labels = F, col="cyan")

text(fdic1,fdic2,labels=levels(varcat), col=c("green", "red"), 
     cex=0.7)
```

# Adding categorical features in the factorial plan to find the correlation between variables.
```{r, include=FALSE}
dcat <- c(2:5,11:14,17:18,20)
colors<-rainbow(length(dcat))

plot(Psi[,eje1],Psi[,eje2], type = "n")
axis(side=1, pos= 0, labels = F, col="cyan")
axis(side=3, pos= 0, labels = F, col="cyan")
axis(side=2, pos= 0, labels = F, col="cyan")
axis(side=4, pos= 0, labels = F, col="cyan")

# Loop to add all categories 

c <- 1
for(k in dcat){
  seguentColor<-colors[c]
  fdic1 = tapply(Psi[,eje1],data[,k],mean)
  fdic2 = tapply(Psi[,eje2],data[,k],mean) 
  
  text(fdic1,fdic2,labels=levels(factor(data[,k])),col=seguentColor, cex=0.6)
  c<-c+1
}
legend("bottomleft",names(data)[dcat],pch=1,col=colors, cex=0.6)

```

# A zoom is required 
```{r, include=FALSE}
plot(Psi[,eje1],Psi[,eje2], type = "n", xlim = c(-3,2), ylim = c(-2,3))
axis(side=1, pos= 0, labels = F, col="cyan")
axis(side=3, pos= 0, labels = F, col="cyan")
axis(side=2, pos= 0, labels = F, col="cyan")
axis(side=4, pos= 0, labels = F, col="cyan")

# Loop to add all categories 

c <- 1
for(k in dcat){
  seguentColor<-colors[c]
  fdic1 = tapply(Psi[,eje1],data[,k],mean)
  fdic2 = tapply(Psi[,eje2],data[,k],mean) 
  
  text(fdic1,fdic2,labels=levels(factor(data[,k])),col=seguentColor, cex=0.6)
  c<-c+1
}
legend("bottomleft",names(data)[dcat],pch=1,col=colors, cex=0.6)

```


# We are plotting too many modalities, so next we will plot them separately.
# Note: There is a bug in the visualization. The last plot seems smaller but when you save the figure all of them have the same size
```{r}
groups <- list(c(2:5), c(11:13), 14, 17, 18, 20)

for(j in 1:length(groups)){
  colors <- c("red", "blue", "darkgreen")
  
  plot(Psi[,eje1],Psi[,eje2], type = "n", xlim = c(-3,2), ylim = c(-2,3))
  axis(side=1, pos= 0, labels = F, col="cyan")
  axis(side=3, pos= 0, labels = F, col="cyan")
  axis(side=2, pos= 0, labels = F, col="cyan")
  axis(side=4, pos= 0, labels = F, col="cyan")
    
    # Loop to add all categories of this group
    c <- 1
    for(k in groups[[j]]){
      seguentColor<-colors[c]
      fdic1 = tapply(Psi[,eje1],data[,k],mean)
      fdic2 = tapply(Psi[,eje2],data[,k],mean) 
      
      text(fdic1,fdic2,labels=levels(factor(data[,k])),col=seguentColor, 
           cex=0.6)
      c <- c+1
    }
  legend("bottomleft",names(data)[groups[[j]]],pch=1,col=colors, cex=0.6)
}


```

# Numerical variables and centroids of desired categorical variables
# Several maps are created to see relations
```{r}
groups <- list(c(2:5), c(11:13))

for(j in 1:length(groups)){
  # colors <- c("red", "darkgreen", "green", "brown", "blue", "purple", "darkorange")
  colors <- c("red", "blue", "darkgreen")
  
  plot(Psi[,eje1],Psi[,eje2], type = "n", xlim = c(-1,2), ylim = c(-1,3))
  axis(side=1, pos= 0, labels = F, col="cyan")
  axis(side=3, pos= 0, labels = F, col="cyan")
  axis(side=2, pos= 0, labels = F, col="cyan")
  axis(side=4, pos= 0, labels = F, col="cyan")
  
  #add projections of numerical variables in background
  arrows(ze, ze, X, Y, length = 0.07,col="gray")
  text(X,Y,labels=etiq,col="gray", cex=0.7)
    
    # Loop to add all categories of this group
    c <- 1
    for(k in groups[[j]]){
      seguentColor<-colors[c]
      fdic1 = tapply(Psi[,eje1],data[,k],mean)
      fdic2 = tapply(Psi[,eje2],data[,k],mean) 
      
      text(fdic1,fdic2,labels=levels(factor(data[,k])),col=seguentColor, 
           cex=0.6)
      c <- c+1
    }
  legend("bottomleft",names(data)[groups[[j]]],pch=1,col=colors, cex=0.6)
}

```


##### Outlier detection #####

# Once we have the PCA (1rst and 2n component), we can use Mahalanobis distance to detect outlier using with a cutoff of 95%. The orange elipse circle project the 95% of confidence level, while the record outside the surface will be considered as outlier

```{r}
# Plot the PCA plan
plot(Psi[,eje1],Psi[,eje2])
axis(side=1, pos= 0, labels = F, col="cyan")
axis(side=3, pos= 0, labels = F, col="cyan")
axis(side=2, pos= 0, labels = F, col="cyan")
axis(side=4, pos= 0, labels = F, col="cyan")

# Defining the parameter for Mahalanobis distance
df <- Psi[,eje1:eje2]
df.center <- colMeans(df)
df.cov <- cov(df)
rad <- sqrt(qchisq(0.95, df = ncol(df)))


# Plotting the ellipse of Mahalanobis distance
ellipse <- data.frame(ellipse(df.center, df.cov, rad, 100, FALSE, col = "orange", fill=TRUE))
```

# Then applying the Mahalanobis distance and the cut-off threshold, we'll find our data treated.
```{r}
# Applying the function
distances <- mahalanobis(x = df, center = df.center, cov = df.cov)

# Defining the Cut-off trigger using Chi-square distance with p = 0.95 df = 2 which in ncol(df)
cutoff <- qchisq(p = 0.95 , df = ncol(df))

# Display all the observations whose distance is greater than the cut-off value.
df[distances > cutoff ,]

# Displan only the observation within the distance
df_clean <- df[distances < cutoff ,]
plot(df_clean, type = "p")
# text(Psi[,eje1],Psi[,eje2],labels=iden,  cex=0.5)
axis(side=1, pos= 0, labels = F, col="cyan")
axis(side=3, pos= 0, labels = F, col="cyan")
axis(side=2, pos= 0, labels = F, col="cyan")
axis(side=4, pos= 0, labels = F, col="cyan")
```


```{r}
#select other axes

eje1 = 3
eje2 = 4

X<-Phi[,eje1]
Y<-Phi[,eje2]

plot(Psi[,eje1],Psi[,eje2],type="n", xlim = c(-.2,1), ylim = c(-1,.2))
axis(side=1, pos= 0, labels = F)
axis(side=3, pos= 0, labels = F)
axis(side=2, pos= 0, labels = F)
axis(side=4, pos= 0, labels = F)
arrows(ze, ze, X, Y, length = 0.07,col="blue")
text(X,Y,labels=etiq,col="darkblue", cex=0.7)
```
It seems that the 4th axis is only related with the id attribute, while the 3rd
might be how often the client accesses the bank. Since they are only
related to variables we already possess, we can conclude that these 
factorial axes aren't relevant in our analysis.

Find relation between age and n_child
```{r}
# df <- data.frame(data$n_child, age)

# Calculate the average age for each n_child value
avg_age <- tapply(data$age, data$n_child, mean)
regression_model <- lm(data$age ~ data$n_child, data = data)
```

```{r}
# Create the scatter plot
plot(names(avg_age), avg_age, xlab = "n_child", ylab = "Average Age", main = "Average Age vs. n_child")
abline(regression_model, col = "blue")
```

Plot avg(age) ~ n_child
```{r}
par(mfrow=c(1,1))
plot (data$n_child, data$age)
```
```{r}
reverse_lm <- lm(data$n_child ~ data$age, data = data)
summary(reverse_lm)

```

```{r}
plot (data$age, data$n_child)
abline(reverse_lm, col = "blue")
```



Regression model results
```{r}
regression_model
summary(regression_model)
```

Regression model plots
```{r}
par(mfrow=c(2,2))
plot(regression_model)
```

